{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing APIs\n",
    "\n",
    "Working out the twitter and llm apis.\n",
    "\n",
    "Currently using the free version of Twitter/X api and Google Flash 2.0 free API. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, os\n",
    "from secrets import google_key, twitter_token\n",
    "\n",
    "twitter_header =  {\"Authorization\": f\"Bearer {twitter_token}\"}\n",
    "google_header = {\"Content-Type\": \"application/json\"}\n",
    "query = \"Brasil deslizamentos de terra\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Twitter API Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Limitations as of right now with the free version: I can only look at recent tweets + there's a really long cooldown time between requests. I would estimate like 30 minutes unless my sense of time is scuffed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_recent(query, max_results= 15):\n",
    "    url  = \"https://api.twitter.com/2/tweets/search/recent\"\n",
    "    params = {\n",
    "        \"query\": query,\n",
    "        \"max_results\": max_results,\n",
    "        \"tweet.fields\": \"created_at,text,author_id\"\n",
    "    }\n",
    "    response = requests.get(url, headers=twitter_header, params= params)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = search_recent(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': [{'created_at': '2025-09-15T14:33:35.000Z', 'id': '1967597671385825399', 'text': 'üåßÔ∏èüåè Chuvas de 2024 no RS provocaram o maior evento de deslizamentos de terra da hist√≥ria do Brasil.\\n\\nüëâ Jo√£o Cunha explica mais aqui: https://t.co/D2anHRkLaT', 'edit_history_tweet_ids': ['1967597671385825399'], 'author_id': '965635296544153600'}], 'meta': {'newest_id': '1967597671385825399', 'oldest_id': '1967597671385825399', 'result_count': 1}}\n"
     ]
    }
   ],
   "source": [
    "print(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code was to transfer my results into a json so I can save it, but lowkey I already wrote over the variable before I could save what I wanted so I just ended up copying and pasting into a document. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "with open(\"tweets01.json\", \"w\", encoding = \"utf-8\") as f: \n",
    "    json.dump(tweets, f, ensure_ascii= False, indent = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, I will test the LLM using a free google api key. I will also use a fake tweet as an argument for the llm prompt before I have "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_tweet = \"\"\"SERIOUS: Avenida Brasil, at the height of Passarela 25, in Iraj√°, completely flooded.\n",
    "\n",
    "This is just the most important expressway in the city of Rio de Janeiro.\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the real tweets, I definitely need to do some preprocessing haha, I can probably use a preprocess function from one of the research papers though, or just make my own. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prompt_gemini(text):\n",
    "    url = f\"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={google_key}\"\n",
    "    data = {\n",
    "        \"contents\": [\n",
    "            {\n",
    "                \"parts\": [\n",
    "                    {\"text\": text}\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    response = requests.post(url, headers = google_header, json= data)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        result = response.json()\n",
    "        try:\n",
    "            return result[\"candidates\"][0][\"content\"][\"parts\"][0][\"text\"]\n",
    "        except (KeyError, IndexError):\n",
    "            print(\"Unexpected response format:\", result)\n",
    "            return None\n",
    "    else:\n",
    "        print(\"Error:\", response.status_code, response.text)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "disaster_types = [\n",
    "        \"Earthquake\",\n",
    "    \"Tsunami\",\n",
    "    \"Flood\",\n",
    "    \"Hurricane\",\n",
    "    \"Wildfire\",\n",
    "    \"Drought\",\n",
    "    \"Heatwave\",\n",
    "    \"Landslide\",\n",
    "    \"Volcano\",\n",
    "    \"Tornado\",\n",
    "    \"Pandemic\",\n",
    "    \"Famine\",\n",
    "    \"Conflict\",\n",
    "    \"Cyberattack\",\n",
    "    \"Blackout\",\n",
    "    \"Chemical Spill\",\n",
    "    \"Nuclear Accident\",\n",
    "    \"Industrial Accident\",\n",
    "    \"Mass Shooting\",\n",
    "    \"Explosion\",\n",
    "    \"Other\",\n",
    "    \"N/A\"\n",
    "]\n",
    "\n",
    "severity_levels = [\n",
    "    \"Severe damage\",\n",
    "\"Mild damage\",\n",
    "\n",
    "\"Little or no damage\",\n",
    "\n",
    "\"Do not know or cannot judge\"\n",
    "]\n",
    "\n",
    "informative_levels = [\n",
    "    \"True\", \n",
    "    \"False\"\n",
    "]\n",
    "\n",
    "impact = [\n",
    "    \"Affected individuals\",\n",
    "    \"Infrastructure and utility damage\",\n",
    "    \"Injured or dead people\",\n",
    "    \"Missing or found people\",\n",
    "    \"Rescue, volunteering, or donation effort\",\n",
    "    \"Vehicle damage\",\n",
    "    \"Other relevant information\",\n",
    "    \"Not relevant\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = prompt_gemini(\n",
    "   f\"\"\"You are a helpful assistant that classifies disaster-related tweets. \n",
    "Classify the following tweet into the categories of main disaster type, severity, informative, and impact. \n",
    "Use the provided keywords for each category to determine the appropriate label. \n",
    "Sentiment must be either positive, negative, or neutral. Location mentioned should be a country or city name if mentioned in the tweet. \n",
    "Respond with the appropriate JSON format. \n",
    "\n",
    "Disaster Types Values List: {', '.join(disaster_types)} \n",
    "Severity Levels Values List: {', '.join(severity_levels)} \n",
    "Informative Levels Values List: {', '.join(informative_levels)} \n",
    "Impact Values List: {', '.join(impact)} \n",
    "\n",
    "Tweet: {fake_tweet}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"Disaster Type\": \"Flood\",\n",
      "  \"Severity Level\": \"Severe damage\",\n",
      "  \"Informative\": \"True\",\n",
      "  \"Impact\": \"Infrastructure and utility damage\",\n",
      "  \"Sentiment\": \"Negative\",\n",
      "  \"Location Mentioned\": \"Rio de Janeiro\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both apis seem to work fine haha, definitely limiting right now since I can't make too many requests."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
