{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from twikit import Client\n",
    "\n",
    "client = Client(\"en-US\")  # locale\n",
    "\n",
    "saved_tweets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Client' object has no attribute 'search'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mfor\u001b[39;00m tweet \u001b[39min\u001b[39;00m client\u001b[39m.\u001b[39;49msearch(\u001b[39m\"\u001b[39m\u001b[39mBrazilian favela\u001b[39m\u001b[39m\"\u001b[39m, limit\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m):\n\u001b[1;32m      2\u001b[0m     saved_tweets\u001b[39m.\u001b[39mappend({\n\u001b[1;32m      3\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mid\u001b[39m\u001b[39m\"\u001b[39m: tweet\u001b[39m.\u001b[39mid,\n\u001b[1;32m      4\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m: tweet\u001b[39m.\u001b[39mtext,\n\u001b[1;32m      5\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39muser\u001b[39m\u001b[39m\"\u001b[39m: tweet\u001b[39m.\u001b[39muser\u001b[39m.\u001b[39musername,\n\u001b[1;32m      6\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcreated_at\u001b[39m\u001b[39m\"\u001b[39m: tweet\u001b[39m.\u001b[39mcreated_at\n\u001b[1;32m      7\u001b[0m     })\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Client' object has no attribute 'search'"
     ]
    }
   ],
   "source": [
    "async for tweet in client.search(\"Brazilian favela\", limit=10):\n",
    "    saved_tweets.append({\n",
    "        \"id\": tweet.id,\n",
    "        \"text\": tweet.text,\n",
    "        \"user\": tweet.user.username,\n",
    "        \"created_at\": tweet.created_at\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_data = asyncio.run(search_tweets())\n",
    "for t in tweets_data:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching page 1...\n"
     ]
    },
    {
     "ename": "Forbidden",
     "evalue": "status: 403, message: \"\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mForbidden\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 35\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[39mreturn\u001b[39;00m all_tweets\n\u001b[1;32m     34\u001b[0m \u001b[39m# In Jupyter, run:\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m favela_tweets \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m scrape_favela_tweets(\u001b[39m\"\u001b[39m\u001b[39mBrazilian favela\u001b[39m\u001b[39m\"\u001b[39m, max_pages\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, tweets_per_page\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[1;32m     37\u001b[0m \u001b[39m# Print results\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m favela_tweets:\n",
      "Cell \u001b[0;32mIn[12], line 15\u001b[0m, in \u001b[0;36mscrape_favela_tweets\u001b[0;34m(query, max_pages, tweets_per_page)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFetching page \u001b[39m\u001b[39m{\u001b[39;00mpage\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[39m# Await the coroutine to get a list of tweets\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m tweets \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m client\u001b[39m.\u001b[39msearch_tweet(query, product\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrealtime\u001b[39m\u001b[39m\"\u001b[39m, count\u001b[39m=\u001b[39mtweets_per_page)\n\u001b[1;32m     17\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m tweets:\n\u001b[1;32m     18\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNo more tweets found.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/brazilian-favela-urop-AQHwoFdT-py3.11/lib/python3.11/site-packages/twikit/client/client.py:731\u001b[0m, in \u001b[0;36mClient.search_tweet\u001b[0;34m(self, query, product, count, cursor)\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    688\u001b[0m \u001b[39mSearches for tweets based on the specified query and\u001b[39;00m\n\u001b[1;32m    689\u001b[0m \u001b[39mproduct type.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[39m>>> previous_tweets = await tweets.previous()\u001b[39;00m\n\u001b[1;32m    728\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    729\u001b[0m product \u001b[39m=\u001b[39m product\u001b[39m.\u001b[39mcapitalize()\n\u001b[0;32m--> 731\u001b[0m response, _ \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgql\u001b[39m.\u001b[39msearch_timeline(query, product, count, cursor)\n\u001b[1;32m    732\u001b[0m instructions \u001b[39m=\u001b[39m find_dict(response, \u001b[39m'\u001b[39m\u001b[39minstructions\u001b[39m\u001b[39m'\u001b[39m, find_one\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    733\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m instructions:\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/brazilian-favela-urop-AQHwoFdT-py3.11/lib/python3.11/site-packages/twikit/client/gql.py:159\u001b[0m, in \u001b[0;36mGQLClient.search_timeline\u001b[0;34m(self, query, product, count, cursor)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[39mif\u001b[39;00m cursor \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    158\u001b[0m     variables[\u001b[39m'\u001b[39m\u001b[39mcursor\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m cursor\n\u001b[0;32m--> 159\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgql_get(Endpoint\u001b[39m.\u001b[39mSEARCH_TIMELINE, variables, FEATURES)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/brazilian-favela-urop-AQHwoFdT-py3.11/lib/python3.11/site-packages/twikit/client/gql.py:124\u001b[0m, in \u001b[0;36mGQLClient.gql_get\u001b[0;34m(self, url, variables, features, headers, extra_params, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[39mif\u001b[39;00m headers \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    123\u001b[0m     headers \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbase\u001b[39m.\u001b[39m_base_headers\n\u001b[0;32m--> 124\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbase\u001b[39m.\u001b[39mget(url, params\u001b[39m=\u001b[39mflatten_params(params), headers\u001b[39m=\u001b[39mheaders, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/brazilian-favela-urop-AQHwoFdT-py3.11/lib/python3.11/site-packages/twikit/client/client.py:211\u001b[0m, in \u001b[0;36mClient.get\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[39masync\u001b[39;00m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mtuple\u001b[39m[\u001b[39mdict\u001b[39m \u001b[39m|\u001b[39m Any, Response]:\n\u001b[1;32m    210\u001b[0m     \u001b[39m'\u001b[39m\u001b[39m:meta private:\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 211\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest(\u001b[39m'\u001b[39m\u001b[39mGET\u001b[39m\u001b[39m'\u001b[39m, url, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/brazilian-favela-urop-AQHwoFdT-py3.11/lib/python3.11/site-packages/twikit/client/client.py:190\u001b[0m, in \u001b[0;36mClient.request\u001b[0;34m(self, method, url, auto_unlock, raise_exception, **kwargs)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[39mraise\u001b[39;00m Unauthorized(message, headers\u001b[39m=\u001b[39mresponse\u001b[39m.\u001b[39mheaders)\n\u001b[1;32m    189\u001b[0m \u001b[39melif\u001b[39;00m status_code \u001b[39m==\u001b[39m \u001b[39m403\u001b[39m:\n\u001b[0;32m--> 190\u001b[0m     \u001b[39mraise\u001b[39;00m Forbidden(message, headers\u001b[39m=\u001b[39mresponse\u001b[39m.\u001b[39mheaders)\n\u001b[1;32m    191\u001b[0m \u001b[39melif\u001b[39;00m status_code \u001b[39m==\u001b[39m \u001b[39m404\u001b[39m:\n\u001b[1;32m    192\u001b[0m     \u001b[39mraise\u001b[39;00m NotFound(message, headers\u001b[39m=\u001b[39mresponse\u001b[39m.\u001b[39mheaders)\n",
      "\u001b[0;31mForbidden\u001b[0m: status: 403, message: \"\""
     ]
    }
   ],
   "source": [
    "from twikit import Client\n",
    "import asyncio\n",
    "import time\n",
    "\n",
    "async def scrape_favela_tweets(query: str, max_pages: int = 5, tweets_per_page: int = 10):\n",
    "    \"\"\"\n",
    "    Scrape tweets matching `query` using Twikit's search_tweet, multiple pages.\n",
    "    \"\"\"\n",
    "    client = Client(\"en-US\")\n",
    "    all_tweets = []\n",
    "\n",
    "    for page in range(max_pages):\n",
    "        print(f\"Fetching page {page + 1}...\")\n",
    "        # Await the coroutine to get a list of tweets\n",
    "        tweets = await client.search_tweet(query, product=\"realtime\", count=tweets_per_page)\n",
    "\n",
    "        if not tweets:\n",
    "            print(\"No more tweets found.\")\n",
    "            break\n",
    "\n",
    "        for tweet in tweets:\n",
    "            all_tweets.append({\n",
    "                \"id\": tweet.id,\n",
    "                \"text\": tweet.text,\n",
    "                \"user\": tweet.user.username,\n",
    "                \"created_at\": tweet.created_at\n",
    "            })\n",
    "\n",
    "        # Optional: wait a bit before fetching the next page to avoid rate limits\n",
    "        await asyncio.sleep(2)\n",
    "\n",
    "    return all_tweets\n",
    "\n",
    "# In Jupyter, run:\n",
    "favela_tweets = await scrape_favela_tweets(\"Brazilian favela\", max_pages=3, tweets_per_page=10)\n",
    "\n",
    "# Print results\n",
    "for t in favela_tweets:\n",
    "    print(t)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.8 ('brazilian-favela-urop-AQHwoFdT-py3.11')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "24eaac1d74d6eef61291c51b2896758e70de1d7dcc43d2fab8692019e3715269"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
